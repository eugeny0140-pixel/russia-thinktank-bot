# russia_thinktank_bot.py
import os
import re
import time
import logging
import requests
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator
import schedule
from dotenv import load_dotenv

load_dotenv()

TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID", "@time_n_John")

if not TELEGRAM_TOKEN:
    raise ValueError("‚ùå TELEGRAM_BOT_TOKEN –Ω–µ –∑–∞–¥–∞–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

# ================== –ò–°–¢–û–ß–ù–ò–ö–ò –° –†–ê–ë–û–ß–ò–ú–ò RSS ==================
# –í–∫–ª—é—á–µ–Ω—ã –¢–û–õ–¨–ö–û —Ç–µ, —É –∫–æ–≥–æ –µ—Å—Ç—å –ø—É–±–ª–∏—á–Ω–∞—è RSS-–ª–µ–Ω—Ç–∞ –∏ –∫–æ—Ç–æ—Ä—ã–µ –¥–æ—Å—Ç—É–ø–Ω—ã –∏–∑ –ï–°/–°–®–ê
SOURCES = [
    # –û—Å–Ω–æ–≤–Ω—ã–µ (–ø—Ä–æ–≤–µ—Ä–µ–Ω—ã –≤–∞–º–∏ –∫–∞–∫ —Ä–∞–±–æ—á–∏–µ)
    {"name": "Foreign Affairs", "url": "https://www.foreignaffairs.com/rss.xml"},
    {"name": "Reuters Institute", "url": "https://reutersinstitute.politics.ox.ac.uk/rss.xml"},
    {"name": "Bruegel", "url": "https://www.bruegel.org/rss.xml"},
    {"name": "E3G", "url": "https://www.e3g.org/feed/"},
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ (—Ä–∞–±–æ—Ç–∞—é—Ç –Ω–∞ Render, –Ω–æ –±–ª–æ–∫–∏—Ä—É—é—Ç—Å—è –∏–∑ –†–§)
    {"name": "Chatham House", "url": "https://www.chathamhouse.org/rss.xml"},
    {"name": "CSIS", "url": "https://www.csis.org/rss.xml"},
    {"name": "Atlantic Council", "url": "https://www.atlanticcouncil.org/feed/"},
    {"name": "RAND Corporation", "url": "https://www.rand.org/rss.xml"},
    {"name": "CFR", "url": "https://www.cfr.org/rss/"},
    {"name": "Carnegie Endowment", "url": "https://carnegieendowment.org/rss.xml"},
    {"name": "The Economist", "url": "https://www.economist.com/latest/rss.xml"},
    {"name": "Bloomberg Politics", "url": "https://www.bloomberg.com/politics/feeds/site.xml"},
]

# ================== –ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê ==================
KEYWORDS = [
    r"\brussia\b", r"\brussian\b", r"\bputin\b", r"\bmoscow\b", r"\bkremlin\b",
    r"\bukraine\b", r"\bukrainian\b", r"\bzelensky\b", r"\bkyiv\b", r"\bkiev\b",
    r"\bcrimea\b", r"\bdonbas\b", r"\bdonetsk\b", r"\bluhansk\b",
    r"\bsanction[s]?\b", r"\bembargo\b", r"\brestrict\b", r"\bprohibit\b",
    r"\bgazprom\b", r"\brosgaz\b", r"\bnord\s?stream\b", r"\byamal\b",
    r"\bwagner\b", r"\bprigozhin\b", r"\bshoigu\b", r"\bmedvedev\b", r"\bpeskov\b", r"\blavrov\b",
    r"\bnato\b", r"\beuropa\b", r"\beuropean\s?union\b", r"\bgermany\b", r"\bfrance\b", r"\busa\b", r"\buk\b",
    r"\bgeopolitic\b", r"\bsecurity\b", r"\bdefense\b", r"\bmilitary\b", r"\bwar\b", r"\bconflict\b",
    r"\bruble\b", r"\brub\b", r"\beconomy\b", r"\benergy\b", r"\boil\b", r"\bgas\b",
    r"\bmoscow\b", r"\bst\s?petersburg\b", r"\bchechnya\b", r"\bdagestan\b",
    r"\bsoviet\b", r"\bussr\b", r"\bpost\W?soviet\b"
]

MAX_SEEN = 5000
MAX_PER_RUN = 12  # —É–≤–µ–ª–∏—á–µ–Ω–æ –∏–∑-–∑–∞ –±–æ–ª—å—à–µ–≥–æ —á–∏—Å–ª–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è (–≤ –ø–∞–º—è—Ç–∏, —Ç–∞–∫ –∫–∞–∫ Render –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∞–π–ª—ã)
seen_links = set()

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
log = logging.getLogger(__name__)

# ================== –§–£–ù–ö–¶–ò–ò ==================

def clean_text(t):
    return re.sub(r"\s+", " ", t).strip()

def translate_to_russian(text):
    try:
        return GoogleTranslator(source='auto', target='ru').translate(text)
    except Exception as e:
        log.warning(f"‚ö†Ô∏è –ü–µ—Ä–µ–≤–æ–¥ –Ω–µ —É–¥–∞–ª—Å—è: {e}")
        return text

def get_summary(title):
    low = title.lower()
    if re.search(r"sanction|embargo|restrict|prohibit", low):
        return "–í–≤–µ–¥–µ–Ω—ã –Ω–æ–≤—ã–µ —Å–∞–Ω–∫—Ü–∏–∏ –∏–ª–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è."
    if re.search(r"attack|strike|bomb|war|invasion|conflict|combat", low):
        return "–°–æ–æ–±—â–∞–µ—Ç—Å—è –æ –≤–æ–µ–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏—è—Ö –∏–ª–∏ —É–¥–∞—Ä–∞—Ö."
    if re.search(r"putin|kremlin|peskov|moscow", low):
        return "–ó–∞—è–≤–ª–µ–Ω–∏–µ –∏–ª–∏ –¥–µ–π—Å—Ç–≤–∏–µ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã –ö—Ä–µ–º–ª—è."
    if re.search(r"economy|rubl?e|oil|gas|gazprom|nord\s?stream|energy", low):
        return "–ù–æ–≤–æ—Å—Ç–∏ —ç–∫–æ–Ω–æ–º–∏–∫–∏, –Ω–µ—Ñ—Ç–∏, –≥–∞–∑–∞ –∏–ª–∏ —Ä—É–±–ª—è."
    if re.search(r"diplomat|talks|negotiat|meeting|lavrov|foreign\s?minist", low):
        return "–î–∏–ø–ª–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã –∏–ª–∏ –∫–æ–Ω—Ç–∞–∫—Ç—ã."
    if re.search(r"wagner|prigozhin|shoigu|medvedev|defense|minist", low):
        return "–°–æ–±—ã—Ç–∏—è —Å —Ä–æ—Å—Å–∏–π—Å–∫–∏–º–∏ –≤–æ–µ–Ω–Ω—ã–º–∏ –∏–ª–∏ –ø–æ–ª–∏—Ç–∏–∫–∞–º–∏."
    if re.search(r"ukraine|zelensky|kyiv|kiev|crimea|donbas", low):
        return "–°–æ–±—ã—Ç–∏—è, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –£–∫—Ä–∞–∏–Ω–æ–π –∏ –ø—Ä–∏–ª–µ–≥–∞—é—â–∏–º–∏ —Ä–µ–≥–∏–æ–Ω–∞–º–∏."
    if re.search(r"nato|europa|european\s?union|germany|france|usa|uk|biden|truss|sunak", low):
        return "–†–µ–∞–∫—Ü–∏—è –∑–∞–ø–∞–¥–Ω—ã—Ö —Å—Ç—Ä–∞–Ω –∏–ª–∏ –ù–ê–¢–û –Ω–∞ —Å–æ–±—ã—Ç–∏—è —Å —É—á–∞—Å—Ç–∏–µ–º –†–æ—Å—Å–∏–∏."
    return "–ê–Ω–∞–ª–∏—Ç–∏–∫–∞, —Å–≤—è–∑–∞–Ω–Ω–∞—è —Å –†–æ—Å—Å–∏–µ–π –∏–ª–∏ –ø–æ—Å—Ç—Å–æ–≤–µ—Ç—Å–∫–∏–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ–º."

def fetch_rss_news():
    global seen_links
    result = []
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    }

    for src in SOURCES:
        if len(result) >= MAX_PER_RUN:
            break
        try:
            url = src["url"].strip()
            log.info(f"üì° {src['name']}")
            resp = requests.get(url, timeout=30, headers=headers)
            resp.raise_for_status()
            soup = BeautifulSoup(resp.content, "xml")

            for item in soup.find_all("item"):
                if len(result) >= MAX_PER_RUN:
                    break

                title = clean_text(item.title.get_text()) if item.title else ""
                link = (item.link.get_text() or item.guid.get_text()).strip() if item.link or item.guid else ""

                if not title or not link or link in seen_links:
                    continue

                if not any(re.search(kw, title, re.IGNORECASE) for kw in KEYWORDS):
                    continue

                ru_title = translate_to_russian(title)
                summary = get_summary(title)
                # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã –¥–ª—è Markdown
                safe_title = ru_title.replace("[", "\\[").replace("]", "\\]").replace("(", "\\(").replace(")", "\\)")
                msg = f"[{safe_title}]({link})\n\n{summary}"
                result.append({"msg": msg, "link": link})

        except Exception as e:
            log.error(f"‚ùå {src['name']}: {e}")

    return result

def send_to_telegram(text):
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHANNEL_ID,
        "text": text,
        "parse_mode": "Markdown",
        "disable_web_page_preview": True,
    }
    try:
        r = requests.post(url, data=payload, timeout=15)
        if r.status_code == 200:
            log.info("‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ")
        else:
            log.error(f"‚ùå Telegram error: {r.text}")
    except Exception as e:
        log.error(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}")

def job():
    global seen_links
    log.info("üîÑ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –†–æ—Å—Å–∏–∏ –∏ –≥–µ–æ–ø–æ–ª–∏—Ç–∏–∫–µ...")
    news = fetch_rss_news()
    if not news:
        log.info("üì≠ –ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–π.")
        return

    for item in news:
        send_to_telegram(item["msg"])
        seen_links.add(item["link"])
        if len(seen_links) > MAX_SEEN:
            seen_links = set(list(seen_links)[-4000:])
        time.sleep(1)

# ================== –ó–ê–ü–£–°–ö ==================
if __name__ == "__main__":
    log.info("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –Ω–∞ Render. –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: %d", len(SOURCES))
    job()
    schedule.every(30).minutes.do(job)

    while True:
        schedule.run_pending()
        time.sleep(1)